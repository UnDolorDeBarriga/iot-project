{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fc0a6b",
   "metadata": {},
   "source": [
    "# On-Device Continual Learning - EMNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee054f7c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2fb7d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc530805",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'emnist/letters',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "label_to_char = {i: chr(97 + i) for i in range(26)}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "for i, example in enumerate(ds_train.take(6)):\n",
    "    image, label = example\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(tf.squeeze(image), cmap='gray')\n",
    "    ax.set_title(f'Label: {label_to_char[label.numpy()-1]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab9f64",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label - 1  # Labels are from 1 to 26 in this dataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ds_train = ds_train.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618b067",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(26, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543d921",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train, validation_data=ds_test, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa943",
   "metadata": {},
   "source": [
    "### Mdel Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(ds_test)\n",
    "print(f'\\nTest accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in ds_test.take(1):\n",
    "    predictions = model(images)\n",
    "    pred_labels = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "    for i in range(6):\n",
    "        ax = axes[i // 3, i % 3]\n",
    "        ax.imshow(tf.squeeze(images[i]), cmap='gray')\n",
    "        ax.set_title(f'True: {label_to_char[labels[i].numpy()]}, Pred: {label_to_char[pred_labels[i].numpy()]}')\n",
    "\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25247896",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e29cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"emnist_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506af9f0",
   "metadata": {},
   "source": [
    "## Model Wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bbcf8",
   "metadata": {},
   "source": [
    "### LittleRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5747c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteRTModule(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        self.loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=[None, 28, 28, 1], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[None], dtype=tf.int32)\n",
    "    ])\n",
    "    def train(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(x, training=True)\n",
    "            loss = self.loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=[None, 28, 28, 1], dtype=tf.float32)\n",
    "    ])\n",
    "    def infer(self, x):\n",
    "        probs = self.model(x, training=False)\n",
    "        return {\"probs\": probs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec9291",
   "metadata": {},
   "source": [
    "### Create Wraped Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "litert_module = LiteRTModule(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97adc4",
   "metadata": {},
   "source": [
    "### Save Model with Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671cafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_DIR = \"saved_model\"\n",
    "\n",
    "tf.saved_model.save(\n",
    "    litert_module,\n",
    "    SAVED_MODEL_DIR,\n",
    "    signatures={\n",
    "        'train': litert_module.train.get_concrete_function(),\n",
    "        'infer': litert_module.infer.get_concrete_function()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74375a2",
   "metadata": {},
   "source": [
    "### Convert to TFLitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,      # Use standard TFLite ops\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS         # Allow fallback to full TF ops if needed\n",
    "]\n",
    "converter.experimental_enable_resource_variables = True  # Enable on-device training\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"emnist_litert_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"emnist_model.keras\")\n",
    "\n",
    "t_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "t_converter.experimental_enable_resource_variables = False\n",
    "\n",
    "t_converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "test_tflite_model = t_converter.convert()\n",
    "\n",
    "with open(\"test_emnist_model_infer_only.tflite\", \"wb\") as f:\n",
    "    f.write(test_tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23624",
   "metadata": {},
   "source": [
    "## Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"test_emnist_model_infer_only.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb35351",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "y_all = []\n",
    "for x_batch, y_batch in ds_test.take(2):  # 2 batches = 128 samples\n",
    "    x_all.append(x_batch.numpy())\n",
    "    y_all.append(y_batch.numpy())\n",
    "\n",
    "x = np.concatenate(x_all, axis=0)\n",
    "y = np.concatenate(y_all, axis=0)\n",
    "\n",
    "num_samples = 100  # Set desired test size\n",
    "\n",
    "# --- Run predictions ---\n",
    "keras_logits = model.predict(x[:num_samples])\n",
    "tflite_logits = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = np.expand_dims(x[i], axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    tflite_logits.append(output)\n",
    "\n",
    "tflite_logits = np.array(tflite_logits)\n",
    "\n",
    "# --- Accuracy ---\n",
    "keras_preds = np.argmax(keras_logits, axis=1)\n",
    "tflite_preds = np.argmax(tflite_logits, axis=1)\n",
    "keras_correct = np.sum(keras_preds == y[:num_samples])\n",
    "tflite_correct = np.sum(tflite_preds == y[:num_samples])\n",
    "\n",
    "# --- Differences ---\n",
    "avg_diff = np.mean(np.abs(keras_logits - tflite_logits))\n",
    "max_diff = np.max(np.abs(keras_logits - tflite_logits))\n",
    "\n",
    "# --- Report ---\n",
    "print(\"📊 Model Comparison Summary\")\n",
    "print(f\"✅ Keras Accuracy:      {keras_correct / num_samples:.4f}\")\n",
    "print(f\"✅ TFLite Accuracy:     {tflite_correct / num_samples:.4f}\")\n",
    "print(f\"📉 Avg Logit Delta:     {avg_diff:.2e}\")\n",
    "print(f\"📈 Max Logit Delta:     {max_diff:.2e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
