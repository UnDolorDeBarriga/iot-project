{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fc0a6b",
   "metadata": {},
   "source": [
    "# On-Device Continual Learning - EMNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd47db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee054f7c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2fb7d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc530805",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t_ds_train, t_ds_test), ds_info = tfds.load(\n",
    "    'emnist/letters',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "ds_full = t_ds_train.concatenate(t_ds_test)\n",
    "label_map = list(string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab9f64",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f5e9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # image = tf.expand_dims(image, -1)\n",
    "    label = label - 1\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b90ea91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "buffer_size = ds_info.splits['train'].num_examples + ds_info.splits['test'].num_examples\n",
    "\n",
    "ds_full = ds_full.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "ds_full = ds_full.shuffle(buffer_size, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b850bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = buffer_size\n",
    "n_train = int(0.8 * total)\n",
    "n_val   = int(0.1 * total)\n",
    "n_test  = total - n_train - n_val\n",
    "\n",
    "ds_train = ds_full.take(n_train)\n",
    "rest = ds_full.skip(n_train)\n",
    "ds_val = rest.take(n_val)\n",
    "ds_test = rest.skip(n_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e068925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train_proc = (\n",
    "    ds_train\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val_proc = (\n",
    "    ds_val\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_test_proc = (\n",
    "    ds_test\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print Numbre exambles in each set\n",
    "\n",
    "\n",
    "# print(\"Train set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_train.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n",
    "# print(\"Validation set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_val.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# # Mostrem el resultat\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n",
    "# print(\"Test set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_test.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# # Mostrem el resultat\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "432721ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "for i, example in enumerate(ds_train_proc.unbatch().take(6)):\n",
    "    image, label = example\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(tf.squeeze(image), cmap='gray')\n",
    "\n",
    "    label_str = label_map[label.numpy()]\n",
    "\n",
    "    ax.set_title(f'Label: {label_str}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618b067",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "def create_cil_model(input_shape=(28,28,1), num_classes=26):\n",
    "    inp = layers.Input(input_shape)\n",
    "\n",
    "    # -------- Bloc 1 --------\n",
    "    x = layers.Conv2D(32, 3, padding='same', name='conv1')(inp)\n",
    "    x = layers.BatchNormalization(name='bn1')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', name='conv1b')(x)\n",
    "    x = layers.BatchNormalization(name='bn1b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D(2, name='pool1')(x)\n",
    "\n",
    "    # -------- Bloc 2 --------\n",
    "    x = layers.Conv2D(64, 3, padding='same', name='conv2')(x)\n",
    "    x = layers.BatchNormalization(name='bn2')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', name='conv2b')(x)\n",
    "    x = layers.BatchNormalization(name='bn2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D(2, name='pool2')(x)\n",
    "\n",
    "    # -------- Embedding --------\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(256, activation='relu', name='features1')(x)\n",
    "    x = layers.Dropout(0.5, name='drop1')(x)\n",
    "    x = layers.Dense(128, activation='relu', name='features2')(x)\n",
    "    x = layers.Dropout(0.5, name='drop2')(x)\n",
    "\n",
    "    # -------- Classificador -------- \n",
    "    logits = layers.Dense(num_classes, name='classifier')(x)\n",
    "    out   = layers.Activation('softmax', name='probabilities')(logits)\n",
    "\n",
    "    model = models.Model(inp, out)\n",
    "\n",
    "    for name in ['conv1','bn1','conv1b','bn1b','pool1']:\n",
    "        model.get_layer(name).trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543d921",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dbc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 36ms/step - accuracy: 0.2904 - loss: 2.4812 - val_accuracy: 0.8220 - val_loss: 0.5976 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 37ms/step - accuracy: 0.7008 - loss: 0.9735 - val_accuracy: 0.8946 - val_loss: 0.3421 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.7939 - loss: 0.6690 - val_accuracy: 0.9109 - val_loss: 0.2888 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 34ms/step - accuracy: 0.8318 - loss: 0.5388 - val_accuracy: 0.9145 - val_loss: 0.2655 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.8572 - loss: 0.4730 - val_accuracy: 0.9274 - val_loss: 0.2237 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.8708 - loss: 0.4208 - val_accuracy: 0.9284 - val_loss: 0.2191 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.8825 - loss: 0.3815 - val_accuracy: 0.9285 - val_loss: 0.2182 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 34ms/step - accuracy: 0.8883 - loss: 0.3580 - val_accuracy: 0.9289 - val_loss: 0.2126 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.8971 - loss: 0.3342 - val_accuracy: 0.9318 - val_loss: 0.1973 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.8987 - loss: 0.3288 - val_accuracy: 0.9377 - val_loss: 0.1858 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 33ms/step - accuracy: 0.9012 - loss: 0.3148 - val_accuracy: 0.9397 - val_loss: 0.1692 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 34ms/step - accuracy: 0.9073 - loss: 0.2924 - val_accuracy: 0.9413 - val_loss: 0.1708 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 33ms/step - accuracy: 0.9094 - loss: 0.2801 - val_accuracy: 0.9476 - val_loss: 0.1562 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 34ms/step - accuracy: 0.9119 - loss: 0.2766 - val_accuracy: 0.9434 - val_loss: 0.1660 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 32ms/step - accuracy: 0.9146 - loss: 0.2669 - val_accuracy: 0.9469 - val_loss: 0.1484 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.9182 - loss: 0.2578 - val_accuracy: 0.9449 - val_loss: 0.1623 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.9193 - loss: 0.2515 - val_accuracy: 0.9459 - val_loss: 0.1562 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.9249 - loss: 0.2269 - val_accuracy: 0.9543 - val_loss: 0.1413 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - accuracy: 0.9305 - loss: 0.2155 - val_accuracy: 0.9569 - val_loss: 0.1320 - learning_rate: 5.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 33ms/step - accuracy: 0.9300 - loss: 0.2156 - val_accuracy: 0.9535 - val_loss: 0.1246 - learning_rate: 5.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.9315 - loss: 0.2094 - val_accuracy: 0.9577 - val_loss: 0.1212 - learning_rate: 5.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.9340 - loss: 0.2036 - val_accuracy: 0.9541 - val_loss: 0.1310 - learning_rate: 5.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 32ms/step - accuracy: 0.9345 - loss: 0.2009 - val_accuracy: 0.9536 - val_loss: 0.1388 - learning_rate: 5.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m1295/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.9359 - loss: 0.1931 - val_accuracy: 0.9608 - val_loss: 0.1089 - learning_rate: 2.5000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m 876/1295\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 34ms/step - accuracy: 0.9365 - loss: 0.1921"
     ]
    }
   ],
   "source": [
    "model = create_cil_model()\n",
    "opt = optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train_proc,\n",
    "    validation_data=ds_val_proc,\n",
    "    epochs=30,\n",
    "    callbacks=cb\n",
    ")\n",
    "\n",
    "# Final test\n",
    "test_loss, test_acc = model.evaluate(ds_test_proc)\n",
    "print(f\"Test Acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa943",
   "metadata": {},
   "source": [
    "### Mdel Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b76ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "label_counts = collections.Counter(y_true)\n",
    "for i in range(26):\n",
    "    print(f\"{label_map[i]}: {label_counts[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loss and accuracy\n",
    "test_loss, test_acc = model.evaluate(ds_test_proc)\n",
    "print(f'\\nTest Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_test_proc:\n",
    "    probs = model.predict(images)\n",
    "    preds = tf.argmax(probs, axis=1).numpy()\n",
    "    y_pred.extend(preds)\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_map, yticklabels=label_map)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report (Precision, Recall, F1):\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in ds_test_proc.take(1):  # MUST be the preprocessed dataset\n",
    "    predictions = model(images)\n",
    "    pred_labels = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "    for i in range(6):\n",
    "        ax = axes[i // 3, i % 3]\n",
    "        ax.imshow(tf.squeeze(images[i]), cmap='gray')\n",
    "\n",
    "        true_char = label_map[labels[i].numpy()]           # 0–25 → 'A'–'Z'\n",
    "        pred_char = label_map[pred_labels[i].numpy()]      # 0–25 → 'A'–'Z'\n",
    "\n",
    "        ax.set_title(f'True: {true_char}, Pred: {pred_char}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25247896",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e29cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"emnist_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506af9f0",
   "metadata": {},
   "source": [
    "## Model Wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bbcf8",
   "metadata": {},
   "source": [
    "### LittleRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5747c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteRTModule(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        self.loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec([None, 28, 28, 1], tf.float32),\n",
    "        tf.TensorSpec([None], tf.int32)\n",
    "    ])\n",
    "    def train(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(x, training=True)\n",
    "            loss = self.loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec([None, 28, 28, 1], tf.float32)\n",
    "    ])\n",
    "    def infer(self, x):\n",
    "        probs = self.model(x, training=False)\n",
    "        return {\"probs\": probs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec9291",
   "metadata": {},
   "source": [
    "### Create Wraped Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "litert_module = LiteRTModule(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97adc4",
   "metadata": {},
   "source": [
    "### Save Model with Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671cafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(\n",
    "    litert_module,\n",
    "    \"saved_model\",\n",
    "    signatures={\n",
    "        'train': litert_module.train.get_concrete_function(),\n",
    "        'infer': litert_module.infer.get_concrete_function()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74375a2",
   "metadata": {},
   "source": [
    "### Convert to TFLitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "converter.experimental_enable_resource_variables = True\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"emnist_litert_model_FIXED.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"emnist_model.keras\")\n",
    "\n",
    "t_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "t_converter.experimental_enable_resource_variables = False\n",
    "\n",
    "t_converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "test_tflite_model = t_converter.convert()\n",
    "\n",
    "with open(\"test_emnist_model_infer_only.tflite\", \"wb\") as f:\n",
    "    f.write(test_tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23624",
   "metadata": {},
   "source": [
    "## Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"test_emnist_model_infer_only.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb35351",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "y_all = []\n",
    "for x_batch, y_batch in ds_test.take(2):  # 2 batches = 128 samples\n",
    "    x_all.append(x_batch.numpy())\n",
    "    y_all.append(y_batch.numpy())\n",
    "\n",
    "x = np.concatenate(x_all, axis=0)\n",
    "y = np.concatenate(y_all, axis=0)\n",
    "\n",
    "num_samples = 100  # Set desired test size\n",
    "\n",
    "# --- Run predictions ---\n",
    "keras_logits = model.predict(x[:num_samples])\n",
    "tflite_logits = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = np.expand_dims(x[i], axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    tflite_logits.append(output)\n",
    "\n",
    "tflite_logits = np.array(tflite_logits)\n",
    "\n",
    "# --- Accuracy ---\n",
    "keras_preds = np.argmax(keras_logits, axis=1)\n",
    "tflite_preds = np.argmax(tflite_logits, axis=1)\n",
    "keras_correct = np.sum(keras_preds == y[:num_samples])\n",
    "tflite_correct = np.sum(tflite_preds == y[:num_samples])\n",
    "\n",
    "# --- Differences ---\n",
    "avg_diff = np.mean(np.abs(keras_logits - tflite_logits))\n",
    "max_diff = np.max(np.abs(keras_logits - tflite_logits))\n",
    "\n",
    "# --- Report ---\n",
    "print(\"📊 Model Comparison Summary\")\n",
    "print(f\"✅ Keras Accuracy:      {keras_correct / num_samples:.4f}\")\n",
    "print(f\"✅ TFLite Accuracy:     {tflite_correct / num_samples:.4f}\")\n",
    "print(f\"📉 Avg Logit Delta:     {avg_diff:.2e}\")\n",
    "print(f\"📈 Max Logit Delta:     {max_diff:.2e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
