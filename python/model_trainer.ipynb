{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fc0a6b",
   "metadata": {},
   "source": [
    "# On-Device Continual Learning - EMNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee054f7c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2fb7d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc530805",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t_ds_train, t_ds_test), ds_info = tfds.load(\n",
    "    'emnist/letters',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "ds_full = t_ds_train.concatenate(t_ds_test)\n",
    "label_map = list(string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab9f64",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # image = tf.expand_dims(image, -1)\n",
    "    label = label - 1\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ea91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "buffer_size = ds_info.splits['train'].num_examples + ds_info.splits['test'].num_examples\n",
    "\n",
    "ds_full = ds_full.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "ds_full = ds_full.shuffle(buffer_size, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b850bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = buffer_size\n",
    "n_train = int(0.8 * total)\n",
    "n_val   = int(0.1 * total)\n",
    "n_test  = total - n_train - n_val\n",
    "\n",
    "ds_train = ds_full.take(n_train)\n",
    "rest = ds_full.skip(n_train)\n",
    "ds_val = rest.take(n_val)\n",
    "ds_test = rest.skip(n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train_proc = (\n",
    "    ds_full\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val_proc = (\n",
    "    ds_val\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_test_proc = (\n",
    "    ds_test\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "tf.data.Dataset.save(\n",
    "    ds_test_proc,\n",
    "    \"../saved_ds/test_proc\",\n",
    "    compression=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print Numbre exambles in each set\n",
    "\n",
    "\n",
    "# print(\"Train set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_train.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n",
    "# print(\"Validation set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_val.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# # Mostrem el resultat\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n",
    "# print(\"Test set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_test.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# # Mostrem el resultat\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432721ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "for i, example in enumerate(ds_train_proc.unbatch().take(6)):\n",
    "    image, label = example\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(tf.squeeze(image), cmap='gray')\n",
    "\n",
    "    label_str = label_map[label.numpy()]\n",
    "\n",
    "    ax.set_title(f'Label: {label_str}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618b067",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "def create_cil_model(input_shape=(28,28,1), num_classes=26):\n",
    "    inp = layers.Input(input_shape)\n",
    "\n",
    "    # -------- Bloc 1 --------\n",
    "    x = layers.Conv2D(32, 3, padding='same', name='conv1')(inp)\n",
    "    x = layers.BatchNormalization(name='bn1')(x)\n",
    "    x = layers.Activation('relu', name='act1')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', name='conv1b')(x)\n",
    "    x = layers.BatchNormalization(name='bn1b')(x)\n",
    "    x = layers.Activation('relu', name='act2')(x)\n",
    "    x = layers.MaxPool2D(2, name='pool1')(x)\n",
    "\n",
    "    # -------- Bloc 2 --------\n",
    "    x = layers.Conv2D(64, 3, padding='same', name='conv2')(x)\n",
    "    x = layers.BatchNormalization(name='bn2')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D(2, name='pool2')(x)\n",
    "\n",
    "    # -------- Embedding --------\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(256, activation='relu', name='features1')(x)\n",
    "    # x = layers.Dropout(0.5, seed=1337, name='drop1')(x)\n",
    "    x = layers.Dense(128, activation='relu', name='features2')(x)\n",
    "    # x = layers.Dropout(0.5, seed=1337, name='drop2')(x)\n",
    "\n",
    "    # -------- Classificador -------- \n",
    "    logits = layers.Dense(num_classes, name='classifier')(x)\n",
    "    out   = layers.Activation('softmax', name='probabilities')(logits)\n",
    "\n",
    "    model = models.Model(inp, out)\n",
    "\n",
    "    for name in ['conv1','bn1','act1','conv1b','bn1b','act2','pool1']:\n",
    "        model.get_layer(name).trainable = False\n",
    "    \n",
    "    # for layer in model.layers:\n",
    "    #     print(f\"{layer.name:15} trainable={layer.trainable}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543d921",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"../models/emnist_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cil_model()\n",
    "opt = optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train_proc,\n",
    "    validation_data=ds_val_proc,\n",
    "    # epochs=20,\n",
    "    epochs=5,\n",
    "    callbacks=cb\n",
    ")\n",
    "\n",
    "# Final test\n",
    "test_loss, test_acc = model.evaluate(ds_test_proc)\n",
    "print(f\"Test Acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa943",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loss and accuracy\n",
    "test_loss, test_acc = model.evaluate(ds_test_proc)\n",
    "print(f'\\nTest Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_test_proc:\n",
    "    probs = model.predict(images)\n",
    "    preds = tf.argmax(probs, axis=1).numpy()\n",
    "    y_pred.extend(preds)\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_map, yticklabels=label_map)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report (Precision, Recall, F1):\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in ds_test_proc.take(1):  # MUST be the preprocessed dataset\n",
    "    predictions = model(images)\n",
    "    pred_labels = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "    for i in range(6):\n",
    "        ax = axes[i // 3, i % 3]\n",
    "        ax.imshow(tf.squeeze(images[i]), cmap='gray')\n",
    "\n",
    "        true_char = label_map[labels[i].numpy()]           # 0â€“25 â†’ 'A'â€“'Z'\n",
    "        pred_char = label_map[pred_labels[i].numpy()]      # 0â€“25 â†’ 'A'â€“'Z'\n",
    "\n",
    "        ax.set_title(f'True: {true_char}, Pred: {pred_char}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25247896",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e29cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/emnist_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506af9f0",
   "metadata": {},
   "source": [
    "## Model Wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bbcf8",
   "metadata": {},
   "source": [
    "### LittleRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5747c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE and TRAINING\n",
    "\n",
    "class LiteRTModule(tf.Module):\n",
    "    def __init__(self, model, dropout_rate=0.5, dropout_seed=1337):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        self.loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout_seed = dropout_seed\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec([None, 28, 28, 1], tf.float32, name=\"images\"),\n",
    "        tf.TensorSpec([None], tf.int64, name=\"labels\")\n",
    "    ])\n",
    "    def train(self, images, labels):\n",
    "        # apply _stateless_ dropout here:\n",
    "        images = tf.nn.dropout(\n",
    "            images,\n",
    "            rate=self.dropout_rate,\n",
    "            seed=self.dropout_seed\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(images, training=True)\n",
    "            loss = self.loss_fn(labels, logits)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec([None, 28, 28, 1], tf.float32, name=\"images\")\n",
    "    ])\n",
    "    def infer(self, images):\n",
    "        probs = self.model(images, training=False)\n",
    "        return {\"probs\": probs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec9291",
   "metadata": {},
   "source": [
    "### Create Wraped Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "litert_module = LiteRTModule(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97adc4",
   "metadata": {},
   "source": [
    "### Save Model with Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671cafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(\n",
    "    litert_module,\n",
    "    \"../models/lit_saved_model\",\n",
    "    signatures={\n",
    "        'train': litert_module.train,\n",
    "        'infer': litert_module.infer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74375a2",
   "metadata": {},
   "source": [
    "### Convert to TFLitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_SUPPORTED_OPS = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "\n",
    "c_train = tf.lite.TFLiteConverter.from_saved_model(\n",
    "    \"../models/lit_saved_model\",\n",
    "    signature_keys=[\"train\",\"infer\"]\n",
    ")\n",
    "c_train.target_spec.supported_ops = COMMON_SUPPORTED_OPS\n",
    "c_train.experimental_enable_resource_variables = True\n",
    "tflite_train = c_train.convert()\n",
    "open(\"../models/emnist_litert_train.tflite\",\"wb\").write(tflite_train)\n",
    "\n",
    "\n",
    "c_infer = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "c_infer.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS ]\n",
    "c_infer.experimental_enable_resource_variables = False\n",
    "tflite_inf = c_infer.convert()\n",
    "open(\"../models/emnist_litert_infer.tflite\",\"wb\").write(tflite_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23624",
   "metadata": {},
   "source": [
    "## Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"../models/emnist_litert_infer.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb35351",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "y_all = []\n",
    "\n",
    "# each x_batch is shape (64,28,28,1), each y_batch is (64,)\n",
    "for x_batch, y_batch in ds_test_proc.take(2):  \n",
    "    x_all.append(x_batch.numpy())\n",
    "    y_all.append(y_batch.numpy())\n",
    "\n",
    "x = np.concatenate(x_all, axis=0)  # -> (128,28,28,1)\n",
    "y = np.concatenate(y_all, axis=0)  # -> (128,)\n",
    "\n",
    "# Now exactly like before:\n",
    "num_samples = 100\n",
    "keras_logits = model.predict(x[:num_samples])\n",
    "tflite_logits = []\n",
    "for i in range(num_samples):\n",
    "    sample = x[i : i+1].astype(np.float32)      # already has leading batch dim\n",
    "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "    interpreter.invoke()\n",
    "    tflite_logits.append(interpreter.get_tensor(output_details[0]['index'])[0])\n",
    "tflite_logits = np.stack(tflite_logits, axis=0)\n",
    "\n",
    "keras_preds  = np.argmax(keras_logits, axis=1)\n",
    "tflite_preds = np.argmax(tflite_logits, axis=1)\n",
    "keras_acc    = np.mean(keras_preds  == y[:num_samples])\n",
    "tflite_acc   = np.mean(tflite_preds == y[:num_samples])\n",
    "avg_diff     = np.mean(np.abs(keras_logits - tflite_logits))\n",
    "max_diff     = np.max (np.abs(keras_logits - tflite_logits))\n",
    "\n",
    "print(\"ðŸ“Š Model Comparison Summary\")\n",
    "print(f\"âœ… Keras Accuracy:      {keras_acc:.4f}\")\n",
    "print(f\"âœ… TFLite Accuracy:     {tflite_acc:.4f}\")\n",
    "print(f\"ðŸ“‰ Avg Logit Delta:     {avg_diff:.2e}\")\n",
    "print(f\"ðŸ“ˆ Max Logit Delta:     {max_diff:.2e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
