{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fc0a6b",
   "metadata": {},
   "source": [
    "# On-Device Continual Learning - EMNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd47db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee054f7c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2fb7d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc530805",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t_ds_train, t_ds_test), ds_info = tfds.load(\n",
    "    'emnist/letters',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "ds_full = t_ds_train.concatenate(t_ds_test)\n",
    "label_map = list(string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab9f64",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5e9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # image = tf.expand_dims(image, -1)\n",
    "    label = label - 1\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90ea91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "buffer_size = ds_info.splits['train'].num_examples + ds_info.splits['test'].num_examples\n",
    "\n",
    "ds_full = ds_full.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "ds_full = ds_full.shuffle(buffer_size, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b850bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = buffer_size\n",
    "n_train = int(0.8 * total)\n",
    "n_val   = int(0.1 * total)\n",
    "n_test  = total - n_train - n_val\n",
    "\n",
    "ds_train = ds_full.take(n_train)\n",
    "rest = ds_full.skip(n_train)\n",
    "ds_val = rest.take(n_val)\n",
    "ds_test = rest.skip(n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e068925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "ds_train_proc = (\n",
    "    ds_full\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val_proc = (\n",
    "    ds_val\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_test_proc = (\n",
    "    ds_test\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "tf.data.Dataset.save(\n",
    "    ds_test_proc,\n",
    "    \"saved_ds/test_proc\",\n",
    "    compression=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print Numbre exambles in each set\n",
    "\n",
    "\n",
    "# print(\"Train set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_train.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n",
    "# print(\"Validation set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_val.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# # Mostrem el resultat\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n",
    "# print(\"Test set:\")\n",
    "# ctr = Counter()\n",
    "# for image, label in ds_test.map(preprocess).as_numpy_iterator():\n",
    "#     ctr[int(label)] += 1\n",
    "\n",
    "# # Mostrem el resultat\n",
    "# for i in range(len(ctr)):\n",
    "#     print(f\"{i} ({label_map[i]}): {ctr[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432721ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "for i, example in enumerate(ds_train_proc.unbatch().take(6)):\n",
    "    image, label = example\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(tf.squeeze(image), cmap='gray')\n",
    "\n",
    "    label_str = label_map[label.numpy()]\n",
    "\n",
    "    ax.set_title(f'Label: {label_str}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618b067",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "def create_cil_model(input_shape=(28,28,1), num_classes=26):\n",
    "    inp = layers.Input(input_shape)\n",
    "\n",
    "    # -------- Bloc 1 --------\n",
    "    x = layers.Conv2D(32, 3, padding='same', name='conv1')(inp)\n",
    "    x = layers.BatchNormalization(name='bn1')(x)\n",
    "    x = layers.Activation('relu', name='act1')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', name='conv1b')(x)\n",
    "    x = layers.BatchNormalization(name='bn1b')(x)\n",
    "    x = layers.Activation('relu', name='act2')(x)\n",
    "    x = layers.MaxPool2D(2, name='pool1')(x)\n",
    "\n",
    "    # -------- Bloc 2 --------\n",
    "    x = layers.Conv2D(64, 3, padding='same', name='conv2')(x)\n",
    "    x = layers.BatchNormalization(name='bn2')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPool2D(2, name='pool2')(x)\n",
    "\n",
    "    # -------- Embedding --------\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(256, activation='relu', name='features1')(x)\n",
    "    # x = layers.Dropout(0.5, seed=1337, name='drop1')(x)\n",
    "    x = layers.Dense(128, activation='relu', name='features2')(x)\n",
    "    # x = layers.Dropout(0.5, seed=1337, name='drop2')(x)\n",
    "\n",
    "    # -------- Classificador -------- \n",
    "    logits = layers.Dense(num_classes, name='classifier')(x)\n",
    "    out   = layers.Activation('softmax', name='probabilities')(logits)\n",
    "\n",
    "    model = models.Model(inp, out)\n",
    "\n",
    "    for name in ['conv1','bn1','act1','conv1b','bn1b','act2','pool1']:\n",
    "        model.get_layer(name).trainable = False\n",
    "    \n",
    "    # for layer in model.layers:\n",
    "    #     print(f\"{layer.name:15} trainable={layer.trainable}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543d921",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"models/emnist_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cil_model()\n",
    "opt = optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train_proc,\n",
    "    validation_data=ds_val_proc,\n",
    "    # epochs=20,\n",
    "    epochs=5,\n",
    "    callbacks=cb\n",
    ")\n",
    "\n",
    "# Final test\n",
    "test_loss, test_acc = model.evaluate(ds_test_proc)\n",
    "print(f\"Test Acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa943",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loss and accuracy\n",
    "test_loss, test_acc = model.evaluate(ds_test_proc)\n",
    "print(f'\\nTest Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_test_proc:\n",
    "    probs = model.predict(images)\n",
    "    preds = tf.argmax(probs, axis=1).numpy()\n",
    "    y_pred.extend(preds)\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_map, yticklabels=label_map)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report (Precision, Recall, F1):\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in ds_test_proc.take(1):  # MUST be the preprocessed dataset\n",
    "    predictions = model(images)\n",
    "    pred_labels = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(8, 6))\n",
    "    for i in range(6):\n",
    "        ax = axes[i // 3, i % 3]\n",
    "        ax.imshow(tf.squeeze(images[i]), cmap='gray')\n",
    "\n",
    "        true_char = label_map[labels[i].numpy()]           # 0â€“25 â†’ 'A'â€“'Z'\n",
    "        pred_char = label_map[pred_labels[i].numpy()]      # 0â€“25 â†’ 'A'â€“'Z'\n",
    "\n",
    "        ax.set_title(f'True: {true_char}, Pred: {pred_char}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25247896",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e29cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/emnist_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506af9f0",
   "metadata": {},
   "source": [
    "## Model Wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bbcf8",
   "metadata": {},
   "source": [
    "### LittleRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5747c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE and TRAINING\n",
    "\n",
    "class LiteRTModule(tf.Module):\n",
    "    def __init__(self, model, dropout_rate=0.5, dropout_seed=1337):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        self.loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout_seed = dropout_seed\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec([None, 28, 28, 1], tf.float32, name=\"images\"),\n",
    "        tf.TensorSpec([None], tf.int64, name=\"labels\")\n",
    "    ])\n",
    "    def train(self, images, labels):\n",
    "        # apply _stateless_ dropout here:\n",
    "        images = tf.nn.dropout(\n",
    "            images,\n",
    "            rate=self.dropout_rate,\n",
    "            seed=self.dropout_seed\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(images, training=True)\n",
    "            loss = self.loss_fn(labels, logits)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec([None, 28, 28, 1], tf.float32, name=\"images\")\n",
    "    ])\n",
    "    def infer(self, images):\n",
    "        probs = self.model(images, training=False)\n",
    "        return {\"probs\": probs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec9291",
   "metadata": {},
   "source": [
    "### Create Wraped Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787b0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "litert_module = LiteRTModule(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97adc4",
   "metadata": {},
   "source": [
    "### Save Model with Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "671cafd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/lit_saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/lit_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    litert_module,\n",
    "    \"models/lit_saved_model\",\n",
    "    signatures={\n",
    "        'train': litert_module.train,\n",
    "        'infer': litert_module.infer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74375a2",
   "metadata": {},
   "source": [
    "### Convert to TFLitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c2b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_3326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_3326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\arnau\\AppData\\Local\\Temp\\tmpb98cm3y8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\arnau\\AppData\\Local\\Temp\\tmpb98cm3y8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\arnau\\AppData\\Local\\Temp\\tmpb98cm3y8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 26), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2188397028624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397031504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397031888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397032080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397030736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397030352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397030544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397032464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397030928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397028432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397029200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397033232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397033424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397035152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402950224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402951376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188397032848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402951184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402950800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402953488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402952912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402954256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402953680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2188402955024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3473536"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMMON_SUPPORTED_OPS = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "\n",
    "c_train = tf.lite.TFLiteConverter.from_saved_model(\n",
    "    \"models/lit_saved_model\",\n",
    "    signature_keys=[\"train\",\"infer\"]\n",
    ")\n",
    "c_train.target_spec.supported_ops = COMMON_SUPPORTED_OPS\n",
    "c_train.experimental_enable_resource_variables = True\n",
    "tflite_train = c_train.convert()\n",
    "open(\"models/emnist_litert_train.tflite\",\"wb\").write(tflite_train)\n",
    "\n",
    "\n",
    "c_infer = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "c_infer.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS ]\n",
    "c_infer.experimental_enable_resource_variables = False\n",
    "tflite_inf = c_infer.convert()\n",
    "open(\"models/emnist_litert_infer.tflite\",\"wb\").write(tflite_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af23624",
   "metadata": {},
   "source": [
    "## Comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081afa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"models/emnist_litert_infer.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb35351",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = []\n",
    "y_all = []\n",
    "\n",
    "# each x_batch is shape (64,28,28,1), each y_batch is (64,)\n",
    "for x_batch, y_batch in ds_test_proc.take(2):  \n",
    "    x_all.append(x_batch.numpy())\n",
    "    y_all.append(y_batch.numpy())\n",
    "\n",
    "x = np.concatenate(x_all, axis=0)  # -> (128,28,28,1)\n",
    "y = np.concatenate(y_all, axis=0)  # -> (128,)\n",
    "\n",
    "# Now exactly like before:\n",
    "num_samples = 100\n",
    "keras_logits = model.predict(x[:num_samples])\n",
    "tflite_logits = []\n",
    "for i in range(num_samples):\n",
    "    sample = x[i : i+1].astype(np.float32)      # already has leading batch dim\n",
    "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "    interpreter.invoke()\n",
    "    tflite_logits.append(interpreter.get_tensor(output_details[0]['index'])[0])\n",
    "tflite_logits = np.stack(tflite_logits, axis=0)\n",
    "\n",
    "keras_preds  = np.argmax(keras_logits, axis=1)\n",
    "tflite_preds = np.argmax(tflite_logits, axis=1)\n",
    "keras_acc    = np.mean(keras_preds  == y[:num_samples])\n",
    "tflite_acc   = np.mean(tflite_preds == y[:num_samples])\n",
    "avg_diff     = np.mean(np.abs(keras_logits - tflite_logits))\n",
    "max_diff     = np.max (np.abs(keras_logits - tflite_logits))\n",
    "\n",
    "print(\"ðŸ“Š Model Comparison Summary\")\n",
    "print(f\"âœ… Keras Accuracy:      {keras_acc:.4f}\")\n",
    "print(f\"âœ… TFLite Accuracy:     {tflite_acc:.4f}\")\n",
    "print(f\"ðŸ“‰ Avg Logit Delta:     {avg_diff:.2e}\")\n",
    "print(f\"ðŸ“ˆ Max Logit Delta:     {max_diff:.2e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
